{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import logging\n",
    "import csv\n",
    "import io\n",
    "import base64\n",
    "import ast\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas  \n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "\n",
    "\n",
    "from flask import Flask, jsonify, request, render_template\n",
    "from flask_cors import CORS \n",
    "from ragutils import ChatGpt, ragChat\n",
    "from langchain_openai import ChatOpenAI\n",
    "import importlib\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "import chromadb.api\n",
    "\n",
    "\n",
    "modelDict = dict()\n",
    "with open ('./shapetalk.csv', 'r', encoding='gbk') as f:\n",
    "    counter = 0\n",
    "    print('initializing')\n",
    "    reader = csv.reader(f)\n",
    "    for row in tqdm(reader):\n",
    "        if (row[6] not in modelDict):\n",
    "            modelDict[row[6]] = set()\n",
    "        for i in range(1, 5):\n",
    "            if (row[i] != ''):\n",
    "                modelDict[row[6]].add(row[i])\n",
    "        counter += 1\n",
    "\n",
    "modelDict.pop('ShapeNet')\n",
    "modelDict.pop('source_object_class')\n",
    "print (modelDict.keys())\n",
    "\n",
    "# for sentence in list(modelDict['vase']):\n",
    "#     vaseDocs.append(Document(page_content=sentence))\n",
    "#     vaseId.append('vase' + str(i))\n",
    "#     i += 1\n",
    "# 构造类名->描述文本，处理描述解析任务\n",
    "source_knowledge_dict = {}\n",
    "for key in modelDict.keys():\n",
    "    print (key + '-' + str(len(list(modelDict[key]))))\n",
    "    source_knowledge_dict[key] = []\n",
    "    sentenCounter = 0\n",
    "    longSentences = ''\n",
    "    for sentence in modelDict[key]:\n",
    "        # 划分一百句为一个整体\n",
    "        if (sentenCounter == 100):\n",
    "            source_knowledge_dict[key].append(longSentences)\n",
    "            longSentences = ''\n",
    "            sentenCounter = 0\n",
    "        longSentences += sentence + '\\n'\n",
    "        sentenCounter += 1\n",
    "    if (sentenCounter > 0):\n",
    "        source_knowledge_dict[key].append(longSentences)\n",
    "        longSentences = ''\n",
    "        sentenCounter = 0\n",
    "        \n",
    "# 构造类名->描述句子，将句子转换为embedding，每类只取200句\n",
    "discriptionDocs = {}\n",
    "for key in modelDict.keys():\n",
    "    sentenCounter = 0\n",
    "    discriptionDocs[key] = []\n",
    "    for sentence in modelDict[key]:\n",
    "        discriptionDocs[key].append(Document(page_content=sentence))\n",
    "        sentenCounter += 1\n",
    "        if (sentenCounter > 200):\n",
    "            sentenCounter = 0\n",
    "            break\n",
    "\n",
    "# print (discriptionDocs)\n",
    "# print (source_knowledge_dict)\n",
    "# source_class = 'cap'\n",
    "# for sentence in modelDict['cap']:\n",
    "#     source_knowledge_cap += sentence + '\\n'\n",
    "# print(source_knowledge_cap)\n",
    "# 这里会消耗巨量tokens，慎用\n",
    "\n",
    "\n",
    "chromadb.api.client.SharedSystemClient.clear_system_cache()\n",
    "embed_model = OpenAIEmbeddings(base_url=\"https://api3.apifans.com/v1\")\n",
    "vectorstore = {}\n",
    "for key in discriptionDocs.keys():\n",
    "    print(f\"\\r当前进度：{key}-{len(discriptionDocs[key])}\", end='')\n",
    "    vs = Chroma.from_documents(documents=discriptionDocs[key], embedding=embed_model, collection_name=\"model_discription_embed\", persist_directory='./discription_embedding/' + key)\n",
    "    vs.persist()\n",
    "    vectorstore[key] = vs\n",
    "print (vectorstore)\n",
    "\n",
    "# for key in discriptionDocs.keys():  \n",
    "#     vectorstore[key].persist()\n",
    "embed_model = OpenAIEmbeddings(base_url=\"https://api3.apifans.com/v1\")\n",
    "query = \"The lips\"\n",
    "# for key in discriptionDocs.keys():\n",
    "#     localDBvectorstore[key] = \n",
    "localvs = Chroma(persist_directory='./discription_embedding/vase', embedding_function=embed_model, collection_name=\"model_discription_embed\")\n",
    "result = localvs.similarity_search(query, k = 5)\n",
    "result[0].page_content\n",
    "# print (localvs)\n",
    "# vectorstore.persist()\n",
    "chromadb.api.client.SharedSystemClient.clear_system_cache()\n",
    "embed_model = OpenAIEmbeddings(base_url=\"https://api3.apifans.com/v1\")\n",
    "vectorstore = {}\n",
    "\n",
    "queryDocs = [\n",
    "    Document(page_content='这个部位有哪些可编辑内容')\n",
    "]\n",
    "\n",
    "\n",
    "vs = Chroma.from_documents(documents=queryDocs, embedding=embed_model, collection_name=\"model_discription_embed\", persist_directory='./discription_embedding/' + key)\n",
    "vs.persist()\n",
    "vectorstore[key] = vs\n",
    "print (vectorstore)\n",
    "\n",
    "\n",
    "for key in source_knowledge_dict.keys():\n",
    "    print (len(source_knowledge_dict[key]))\n",
    "ragClient = ragChat()\n",
    "source_knowledge = 'The target\\'s foot is more round and the vase is with builtiful color, the top of it has a longger head\\nThe top of the vase is open\\nThe vase has flowers in it'\n",
    "modelClass = 'vase'\n",
    "prompt_template1 = f\"\"\"以下内容为对一个{modelClass}的描述集合，将以下内容中的每一句按照格式以键值字典的方式拆分，键为该物体的部位，如果是对整体的描述则直接用{modelClass}作为键，值为该部位对应的描述。请返回给我一个键值字典列表，列表中每一项为一个键值字典。不要使用代码格式返回:\n",
    "\n",
    "内容:\n",
    "{source_knowledge}\n",
    "\n",
    "\"\"\"\n",
    "ragClient.pushUserMessage(prompt_template1)\n",
    "\n",
    "# 以下操作消耗大量tokens\n",
    "answer = ragClient.getandpushGptMsg()\n",
    "ragClient.MessageHistory()\n",
    "# ragClient = ragChat()\n",
    "\n",
    "# dict_keys(['faucet', 'cap', 'plant', 'cabinet', 'bookshelf', 'knife', 'table', \n",
    "# 'skateboard', 'mug', 'vase', 'pistol', 'flowerpot', 'clock', 'chair', 'bathtub', \n",
    "# 'bottle', 'display', 'bag', 'trashbin', 'scissors', 'person', 'helmet', 'bowl', \n",
    "# 'airplane', 'guitar', 'dresser', 'bed', 'sofa', 'bench', 'lamp'])\n",
    "part2Discription = {}\n",
    "for modelClass in source_knowledge_dict.keys():\n",
    "    # 先不处理长度大于一百万的句子，tokens撑不住\n",
    "# modelClass = 'faucet'\n",
    "    # if (len(source_knowledge_dict[modelClass]) < 10):\n",
    "    discription = dict()\n",
    "    index = 0\n",
    "    for sentences in source_knowledge_dict[modelClass]:\n",
    "        # 为了节省tokens，每个类只取前200句得了\n",
    "        if (index > 1):\n",
    "            break\n",
    "        print(f\"\\r当前进度：{modelClass}-{index}\", end='')\n",
    "        index += 1\n",
    "        prompt_template1 = f\"\"\"以下内容为对一个{modelClass}的描述集合，将以下内容中的每一句按照格式以键值字典的方式拆分，键为该物体的部位，如果是对整体的描述则直接用{modelClass}作为键，值为该部位对应的描述。请返回给我一个python键值字典列表，列表中每一项为一个键值字典。不要使用代码格式返回:\n",
    "    \n",
    "        内容:\n",
    "        {sentences}\n",
    "        \"\"\"\n",
    "        ragClient.pushUserMessage(prompt_template1)\n",
    "        answer = ragClient.getGptMsg()\n",
    "        parsedStr = json.loads(answer)\n",
    "        for dictEle in parsedStr:\n",
    "            for key in dictEle.keys():\n",
    "                if key in discription:\n",
    "                    discription[key].add(dictEle[key])\n",
    "                else:\n",
    "                    discription[key] = set()\n",
    "                    discription[key].add(dictEle[key])\n",
    "        ragClient.deleteMessage()\n",
    "    for key in discription.keys():\n",
    "        discription[key] = list(discription[key])\n",
    "    part2Discription[modelClass] = discription\n",
    "\n",
    "\n",
    "print (part2Discription['lamp'])\n",
    "# answer = '''[\n",
    "#   {\"foot\": \"more round\"},\n",
    "#   {\"vase\": \"with beautiful color\"},\n",
    "#   {\"top\": \"has a longer head\"},\n",
    "#   {\"top\": \"is open\"},\n",
    "#   {\"vase\": \"has flowers in it\"},\n",
    "#   {\"top\": \"has a longer head\"}]'''\n",
    "# answer += ''\n",
    "# print (answer)\n",
    "# print (answer)\n",
    "# parsedStr = json.loads(answer)\n",
    "\n",
    "# vasePart2Discription = {}\n",
    "# for dictEle in parsedStr:\n",
    "#     for key in dictEle.keys():\n",
    "#         if key in vasePart2Discription:\n",
    "#             vasePart2Discription[key].add(dictEle[key])\n",
    "#         else:\n",
    "#             vasePart2Discription[key] = set()\n",
    "#             vasePart2Discription[key].add(dictEle[key])\n",
    "# # print (vasePart2Discription)\n",
    "# for key in vasePart2Discription.keys():\n",
    "#     vasePart2Discription[key] = list(vasePart2Discription[key])\n",
    "with open('Part2Discription', 'w') as f:\n",
    "    json.dump(part2Discription, f, indent=4)\n",
    "# 1：这个是基于用户问答做反馈\n",
    "ragClient = ragChat()\n",
    "Part2Discription = {}\n",
    "with open('Part2Discription', 'r') as f:\n",
    "    Part2Discription = json.load(f)\n",
    "query = '请问我可以对Brim做什么改动？'\n",
    "query = '你今天吃了吗'\n",
    "\n",
    "# 这里可以存储多个prompt模板，用来匹配用户输入prompt和哪个模板更匹配，如果匹配上了就按结构返回，没匹配上就自由返回\n",
    "prompt_template2 = f\"\"\"请基于以下数据库回答问题，该数据库为一个字典结构，键值为cap类物体拥有的部位名称，值为该部位可用的描述信息。你需要返回的内容格式为 {{\"answer\": \"...\", \"discription\": {{\"...\":[\"...\"], \"...\":[\"...\"], \"...\":[\"...\"]}}}}，\"answer\"为你对query的回答，\"discription\"为数据库中与query最相关的三个部位，每个部位提供三条描述内容，不要翻译。如果用户提问与物品部位与描述无关，则\"discription\"的值为空即可\n",
    "\n",
    "数据库:\n",
    "{Part2Discription['cap']}\n",
    "query:\n",
    "{query}\n",
    "\"\"\"\n",
    "ragClient.pushUserMessage(prompt_template2)\n",
    "answer = ragClient.getandpushGptMsg()\n",
    "print (answer)\n",
    "\n",
    "# 2：对用户输入prompt进行编码，做embedding相似的编辑方向推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130343it [00:00, 145688.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['faucet', 'cap', 'plant', 'cabinet', 'bookshelf', 'knife', 'table', 'skateboard', 'mug', 'vase', 'pistol', 'flowerpot', 'clock', 'chair', 'bathtub', 'bottle', 'display', 'bag', 'trashbin', 'scissors', 'person', 'helmet', 'bowl', 'airplane', 'guitar', 'dresser', 'bed', 'sofa', 'bench', 'lamp'])\n",
      "faucet-7041\n",
      "cap-2094\n",
      "plant-2687\n",
      "cabinet-2578\n",
      "bookshelf-8247\n",
      "knife-4915\n",
      "table-46480\n",
      "skateboard-1980\n",
      "mug-1491\n",
      "vase-7016\n",
      "pistol-3660\n",
      "flowerpot-5625\n",
      "clock-6116\n",
      "chair-39479\n",
      "bathtub-8594\n",
      "bottle-4149\n",
      "display-8047\n",
      "bag-2726\n",
      "trashbin-4056\n",
      "scissors-715\n",
      "person-1768\n",
      "helmet-1451\n",
      "bowl-1852\n",
      "airplane-24645\n",
      "guitar-6823\n",
      "dresser-12808\n",
      "bed-6860\n",
      "sofa-29684\n",
      "bench-14045\n",
      "lamp-36758\n"
     ]
    }
   ],
   "source": [
    "modelDict = dict()\n",
    "with open ('./shapetalk.csv', 'r', encoding='gbk') as f:\n",
    "    counter = 0\n",
    "    print('initializing')\n",
    "    reader = csv.reader(f)\n",
    "    for row in tqdm(reader):\n",
    "        if (row[6] not in modelDict):\n",
    "            modelDict[row[6]] = set()\n",
    "        for i in range(1, 5):\n",
    "            if (row[i] != ''):\n",
    "                modelDict[row[6]].add(row[i])\n",
    "        counter += 1\n",
    "\n",
    "modelDict.pop('ShapeNet')\n",
    "modelDict.pop('source_object_class')\n",
    "print (modelDict.keys())\n",
    "\n",
    "# for sentence in list(modelDict['vase']):\n",
    "#     vaseDocs.append(Document(page_content=sentence))\n",
    "#     vaseId.append('vase' + str(i))\n",
    "#     i += 1\n",
    "# 构造类名->描述文本，处理描述解析任务\n",
    "source_knowledge_dict = {}\n",
    "for key in modelDict.keys():\n",
    "    print (key + '-' + str(len(list(modelDict[key]))))\n",
    "    source_knowledge_dict[key] = []\n",
    "    sentenCounter = 0\n",
    "    longSentences = ''\n",
    "    for sentence in modelDict[key]:\n",
    "        # 划分一百句为一个整体\n",
    "        if (sentenCounter == 100):\n",
    "            source_knowledge_dict[key].append(longSentences)\n",
    "            longSentences = ''\n",
    "            sentenCounter = 0\n",
    "        longSentences += sentence + '\\n'\n",
    "        sentenCounter += 1\n",
    "    if (sentenCounter > 0):\n",
    "        source_knowledge_dict[key].append(longSentences)\n",
    "        longSentences = ''\n",
    "        sentenCounter = 0\n",
    "        \n",
    "# 构造类名->描述句子，将句子转换为embedding，每类只取200句\n",
    "discriptionDocs = {}\n",
    "for key in modelDict.keys():\n",
    "    sentenCounter = 0\n",
    "    discriptionDocs[key] = []\n",
    "    for sentence in modelDict[key]:\n",
    "        discriptionDocs[key].append(Document(page_content=sentence))\n",
    "        sentenCounter += 1\n",
    "        if (sentenCounter > 200):\n",
    "            sentenCounter = 0\n",
    "            break\n",
    "\n",
    "# print (discriptionDocs)\n",
    "# print (source_knowledge_dict)\n",
    "# source_class = 'cap'\n",
    "# for sentence in modelDict['cap']:\n",
    "#     source_knowledge_cap += sentence + '\\n'\n",
    "# print(source_knowledge_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前进度：lamp-201101111{'faucet': <langchain_community.vectorstores.chroma.Chroma object at 0x7f7535fbf6d0>, 'cap': <langchain_community.vectorstores.chroma.Chroma object at 0x7f732d8652a0>, 'plant': <langchain_community.vectorstores.chroma.Chroma object at 0x7f753c0ecb20>, 'cabinet': <langchain_community.vectorstores.chroma.Chroma object at 0x7f732d88d990>, 'bookshelf': <langchain_community.vectorstores.chroma.Chroma object at 0x7f73531d8bb0>, 'knife': <langchain_community.vectorstores.chroma.Chroma object at 0x7f732fe3b730>, 'table': <langchain_community.vectorstores.chroma.Chroma object at 0x7f7517a7c880>, 'skateboard': <langchain_community.vectorstores.chroma.Chroma object at 0x7f750b5f0430>, 'mug': <langchain_community.vectorstores.chroma.Chroma object at 0x7f73536aeb30>, 'vase': <langchain_community.vectorstores.chroma.Chroma object at 0x7f732e27b1c0>, 'pistol': <langchain_community.vectorstores.chroma.Chroma object at 0x7f754cc0b160>, 'flowerpot': <langchain_community.vectorstores.chroma.Chroma object at 0x7f732b9df550>, 'clock': <langchain_community.vectorstores.chroma.Chroma object at 0x7f753c0c68f0>, 'chair': <langchain_community.vectorstores.chroma.Chroma object at 0x7f7330068430>, 'bathtub': <langchain_community.vectorstores.chroma.Chroma object at 0x7f754c9cd270>, 'bottle': <langchain_community.vectorstores.chroma.Chroma object at 0x7f732d88eec0>, 'display': <langchain_community.vectorstores.chroma.Chroma object at 0x7f753be533a0>, 'bag': <langchain_community.vectorstores.chroma.Chroma object at 0x7f73531d9180>, 'trashbin': <langchain_community.vectorstores.chroma.Chroma object at 0x7f7498008e50>, 'scissors': <langchain_community.vectorstores.chroma.Chroma object at 0x7f749dfb9e40>, 'person': <langchain_community.vectorstores.chroma.Chroma object at 0x7f7535c51ab0>, 'helmet': <langchain_community.vectorstores.chroma.Chroma object at 0x7f753aae4f10>, 'bowl': <langchain_community.vectorstores.chroma.Chroma object at 0x7f7518696680>, 'airplane': <langchain_community.vectorstores.chroma.Chroma object at 0x7f74f9e4f460>, 'guitar': <langchain_community.vectorstores.chroma.Chroma object at 0x7f753bedd720>, 'dresser': <langchain_community.vectorstores.chroma.Chroma object at 0x7f732dd0fcd0>, 'bed': <langchain_community.vectorstores.chroma.Chroma object at 0x7f7330075fc0>, 'sofa': <langchain_community.vectorstores.chroma.Chroma object at 0x7f754c9c1360>, 'bench': <langchain_community.vectorstores.chroma.Chroma object at 0x7f732fe3ab60>, 'lamp': <langchain_community.vectorstores.chroma.Chroma object at 0x7f7518592110>}\n"
     ]
    }
   ],
   "source": [
    "# 这里会消耗巨量tokens，慎用\n",
    "\n",
    "\n",
    "chromadb.api.client.SharedSystemClient.clear_system_cache()\n",
    "embed_model = OpenAIEmbeddings(base_url=\"https://api3.apifans.com/v1\")\n",
    "vectorstore = {}\n",
    "for key in discriptionDocs.keys():\n",
    "    print(f\"\\r当前进度：{key}-{len(discriptionDocs[key])}\", end='')\n",
    "    vs = Chroma.from_documents(documents=discriptionDocs[key], embedding=embed_model, collection_name=\"model_discription_embed\", persist_directory='./discription_embedding/' + key)\n",
    "    vs.persist()\n",
    "    vectorstore[key] = vs\n",
    "print (vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The lips are more pronounced.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# for key in discriptionDocs.keys():  \n",
    "#     vectorstore[key].persist()\n",
    "embed_model = OpenAIEmbeddings(base_url=\"https://api3.apifans.com/v1\")\n",
    "query = \"The lips\"\n",
    "# for key in discriptionDocs.keys():\n",
    "#     localDBvectorstore[key] = \n",
    "localvs = Chroma(persist_directory='./discription_embedding/vase', embedding_function=embed_model, collection_name=\"model_discription_embed\")\n",
    "result = localvs.similarity_search(query, k = 5)\n",
    "result[0].page_content\n",
    "# print (localvs)\n",
    "# vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "21\n",
      "27\n",
      "26\n",
      "83\n",
      "50\n",
      "465\n",
      "20\n",
      "15\n",
      "71\n",
      "37\n",
      "57\n",
      "62\n",
      "395\n",
      "86\n",
      "42\n",
      "81\n",
      "28\n",
      "41\n",
      "8\n",
      "18\n",
      "15\n",
      "19\n",
      "247\n",
      "69\n",
      "129\n",
      "69\n",
      "297\n",
      "141\n",
      "368\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for key in source_knowledge_dict.keys():\n",
    "    print (len(source_knowledge_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 以下内容为对一个vase的描述集合，将以下内容中的每一句按照格式以键值字典的方式拆分，键为该物体的部位，如果是对整体的描述则直接用vase作为键，值为该部位对应的描述。请返回给我一个键值字典列表，列表中每一项为一个键值字典。不要使用代码格式返回:\n",
      "\n",
      "内容:\n",
      "The target's foot is more round and the vase is with builtiful color, the top of it has a longger head\n",
      "The top of the vase is open\n",
      "The vase has flowers in it\n",
      "\n",
      "\n",
      "*************************************************\n",
      "AI: [\n",
      "  {\"foot\": \"more round\"},\n",
      "  {\"vase\": \"with beautiful color\"},\n",
      "  {\"top\": \"has a longer head\"},\n",
      "  {\"top\": \"is open\"},\n",
      "  {\"vase\": \"has flowers in it\"}\n",
      "]\n",
      "*************************************************\n"
     ]
    }
   ],
   "source": [
    "ragClient = ragChat()\n",
    "source_knowledge = 'The target\\'s foot is more round and the vase is with builtiful color, the top of it has a longger head\\nThe top of the vase is open\\nThe vase has flowers in it'\n",
    "modelClass = 'vase'\n",
    "prompt_template1 = f\"\"\"以下内容为对一个{modelClass}的描述集合，将以下内容中的每一句按照格式以键值字典的方式拆分，键为该物体的部位，如果是对整体的描述则直接用{modelClass}作为键，值为该部位对应的描述。请返回给我一个键值字典列表，列表中每一项为一个键值字典。不要使用代码格式返回:\n",
    "\n",
    "内容:\n",
    "{source_knowledge}\n",
    "\n",
    "\"\"\"\n",
    "ragClient.pushUserMessage(prompt_template1)\n",
    "\n",
    "# 以下操作消耗大量tokens\n",
    "answer = ragClient.getandpushGptMsg()\n",
    "ragClient.MessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前进度：lamp-11-1111"
     ]
    }
   ],
   "source": [
    "# ragClient = ragChat()\n",
    "\n",
    "# dict_keys(['faucet', 'cap', 'plant', 'cabinet', 'bookshelf', 'knife', 'table', \n",
    "# 'skateboard', 'mug', 'vase', 'pistol', 'flowerpot', 'clock', 'chair', 'bathtub', \n",
    "# 'bottle', 'display', 'bag', 'trashbin', 'scissors', 'person', 'helmet', 'bowl', \n",
    "# 'airplane', 'guitar', 'dresser', 'bed', 'sofa', 'bench', 'lamp'])\n",
    "part2Discription = {}\n",
    "for modelClass in source_knowledge_dict.keys():\n",
    "    # 先不处理长度大于一百万的句子，tokens撑不住\n",
    "# modelClass = 'faucet'\n",
    "    # if (len(source_knowledge_dict[modelClass]) < 10):\n",
    "    discription = dict()\n",
    "    index = 0\n",
    "    for sentences in source_knowledge_dict[modelClass]:\n",
    "        # 为了节省tokens，每个类只取前200句得了\n",
    "        if (index > 1):\n",
    "            break\n",
    "        print(f\"\\r当前进度：{modelClass}-{index}\", end='')\n",
    "        index += 1\n",
    "        prompt_template1 = f\"\"\"以下内容为对一个{modelClass}的描述集合，将以下内容中的每一句按照格式以键值字典的方式拆分，键为该物体的部位，如果是对整体的描述则直接用{modelClass}作为键，值为该部位对应的描述。请返回给我一个python键值字典列表，列表中每一项为一个键值字典。不要使用代码格式返回:\n",
    "    \n",
    "        内容:\n",
    "        {sentences}\n",
    "        \"\"\"\n",
    "        ragClient.pushUserMessage(prompt_template1)\n",
    "        answer = ragClient.getGptMsg()\n",
    "        parsedStr = json.loads(answer)\n",
    "        for dictEle in parsedStr:\n",
    "            for key in dictEle.keys():\n",
    "                if key in discription:\n",
    "                    discription[key].add(dictEle[key])\n",
    "                else:\n",
    "                    discription[key] = set()\n",
    "                    discription[key].add(dictEle[key])\n",
    "        ragClient.deleteMessage()\n",
    "    for key in discription.keys():\n",
    "        discription[key] = list(discription[key])\n",
    "    part2Discription[modelClass] = discription\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top': ['pointy', 'hat shaped', 'has triangles and a ball shape in the middle', 'is larger than its bottom'], 'feet': ['3 small under the square base'], 'tube': ['is curved', 'has a rounded bend at the top', 'does not extend out beyond the footprint of the base', 'longest is thinner', 'thinner'], 'shade': ['does not have a circular shape', 'contains a tassel', 'has a taper square shape', 'is tulip shaped', 'extended out by thin chords', 'very small and scooped shaped', 'Pembroke Empire shape', 'longer and wider', 'comes to more of a point', \"isn't solid\", 'has rod in the center', 'has a conical top', 'pointed at the top', 'conical shade points the light straight up', 'does not have a scalloped top', 'is longer', 'is a separate part, not part of the lamp itself', 'has gaps in it', 'rounder, globular', 'does not have a shape like a half cylinder', 'tapered drum', 'not as wide', 'smaller opening', 'has an open top', 'resembles a book', 'has sphere in the middle', 'giant', 'long, vertical and flared upward toward ceiling', 'does not have a metal grate at the bottom', 'has a chain hanging down from it', 'is more narrow on the top', 'is held by five thin chains', 'is more square', 'has an indent line that cuts into its lower mid section'], 'light post': ['visible and cylindrical'], 'lamp': ['not a full ball shape', 'has two lights', 'has a single long pole', 'ceiling rather than a desk', \"doesn't have a pull cord\", 'does not have an element which can extend as far', 'has scrollwork details', 'does not have significant vertical lines', 'has two poles', 'has a more curly shape', 'does not have any visible cables', 'shorter in length', 'has a canopy', 'hanging', 'not cone shaped', 'much less height', 'does not have a base', 'has three supporting cables', \"doesn't have a lamp shade\", 'is shaped like a candle', 'has no solid base', 'does not have an adjustable neck', 'has two lamps', 'has nothing on the top', 'ornate', 'has a different lampshade', 'does not have a square shade', 'has a cable', 'has a cage over the bulb', 'has tiny poles sticking out of the side', 'has no circular divots', 'single', 'two wires', 'slightly taller', 'has a longer pole which extends from the base', \"doesn't have a rounded shade\", 'lacks a shade', 'sits in a frame', 'has no flat base', 'has a very thin pole holding it up', 'has numerous shades', 'has five lights', '3 light fixtures', 'has a tripod stand', 'hangs lower', 'does not have a sphere at the top', 'only nine bulbs'], 'stem': ['longer'], 'light portion': ['not as slimmer'], 'pole': ['larger', 'is straight with no intersecting decorations', 'is longer', 'is taller', 'coming down from the bottom of the shade is visible through the tripod', 'is considerably thinner throughout and thinnest at top, near shade', 'shorter, fatter', \"is not visible through shade's top\", 'lo9nger'], 'body': ['more curved', 'shaped like a cup or a trophy', 'rounded', 'is more arched', 'rectangular', 'gets smaller as it gets higher', 'contains bands', 'thicker'], 'base': ['not rectangular', 'not as smooth', 'slightly smaller around', 'is long and flat', 'is smoother', 'rectangular', 'angles up into the tube', 'much wider', 'is flat, circle shaped', 'contains circular decorations', 'is horn shaped', 'straight', 'tripod', 'is smaller', 'organic shape', 'square bottom', 'larger diameter', 'is larger', 'more intricate', 'consists of two parts', 'is shaped like a square', 'conical decorative', 'is more square', 'is conical (versus flat)', 'is less complex'], 'arms': ['curved'], 'middle': ['wheel shaped thing'], 'lightshade': ['thicker, rounded edges'], 'arm': ['bends to the right side', 'curves on the bottom'], 'pipe': ['on the outside of the rod is shorter'], 'post': ['very thin'], 'canopy': ['rectangular in shape and is wider'], 'center arm': ['shaped like a man'], 'lock': ['not visible'], 'pole carvings': ['more angular'], 'cable': ['shorter'], 'distractor': ['has something in it where the target looks empty by comparison', 'has four squished balls in the middle', \"has four feet that resemble an 'X'\"], 'connecting joint': ['more curved'], 'angles': ['hard'], 'frame': ['visible in the shade'], 'corners': ['2 curved pointed'], 'support rods': ['six that end in hooks'], 'lamp shade': ['is exposed on top so you can see the light bulb', 'smoother'], 'ring clips': ['2 around the pole at one end'], 'pole/wire': ['thinner'], 'shade top': ['plain', 'has a hanging loop attached'], 'head on the smaller arm': ['facing down'], 'light shade': ['donut shape'], 'vertical part': ['slimmer'], 'disc': ['small on the chain attaching it to the base'], 'vertical arms': ['thick'], 'lampshade': ['is thinner', 'is disc shaped'], 'holder': ['is a bit thicker'], 'hoops': ['are more closely spaced together'], 'top attachment': ['to the ceiling is half a sphere'], 'light bulb section': ['is shorter'], 'rod': ['extends out of the main post where the shade is connected'], 'bottom base': ['is more rectangle'], 'attachment': ['to the wire is tapered'], 'center': ['contains a long tube', \"cuts through the lamp shade's center\"], 'neck': ['is shorter', 'is tapered'], 'cable or wire hub': ['is larger'], 'above base': ['has a battery pack'], 'box at the top': ['is thicker'], 'area to place the bulb': ['is shorter'], 'bulb': ['is hemispherical'], 'lamp head': ['is longer and more tube-shaped', 'consists of many rounded oblong panels forming a spherical shape'], 'disk at the top': ['is thicker'], 'handle': ['has an additional large screw that is at a 45 degree angle to the fixture'], 'parts': ['are not in the same direction but different directions'], 'domes': ['are rounded'], 'light': ['points towards the ground', 'is not made from flat plates'], 'bar': ['does NOT make a T shape'], 'side bulb': ['has a larger, curved pole'], 'lamp base': ['is smaller circumference'], 'bottom part': ['is thicker'], 'central globe': ['is above the chandelier'], 'poles': ['are curved'], \"shade's inner part\": ['is more longer']}\n"
     ]
    }
   ],
   "source": [
    "print (part2Discription['lamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer = '''[\n",
    "#   {\"foot\": \"more round\"},\n",
    "#   {\"vase\": \"with beautiful color\"},\n",
    "#   {\"top\": \"has a longer head\"},\n",
    "#   {\"top\": \"is open\"},\n",
    "#   {\"vase\": \"has flowers in it\"},\n",
    "#   {\"top\": \"has a longer head\"}]'''\n",
    "# answer += ''\n",
    "# print (answer)\n",
    "# print (answer)\n",
    "# parsedStr = json.loads(answer)\n",
    "\n",
    "# vasePart2Discription = {}\n",
    "# for dictEle in parsedStr:\n",
    "#     for key in dictEle.keys():\n",
    "#         if key in vasePart2Discription:\n",
    "#             vasePart2Discription[key].add(dictEle[key])\n",
    "#         else:\n",
    "#             vasePart2Discription[key] = set()\n",
    "#             vasePart2Discription[key].add(dictEle[key])\n",
    "# # print (vasePart2Discription)\n",
    "# for key in vasePart2Discription.keys():\n",
    "#     vasePart2Discription[key] = list(vasePart2Discription[key])\n",
    "with open('Part2Discription', 'w') as f:\n",
    "    json.dump(part2Discription, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RAG_langchain-main/ragutils.py:75: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  receiveMsg = self.langchinChat(self.msgs).content\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'brim': ['thinner vertically', 'is taller vertically', 'circular all the way around', 'goes around the entire hat', 'flat', 'wider and asymmetrical', 'thin', 'is thinner', 'turns downward', 'smaller diameter', 'is puffed out', 'extends out and is more squarish at the front', 'thicker', 'only covers the front', 'thinner', 'diameter is smaller', 'rounded', 'faces downward', 'does not go all the way around', 'thinner around hat']\n"
     ]
    }
   ],
   "source": [
    "# 1：这个是基于用户问答做反馈\n",
    "ragClient = ragChat()\n",
    "Part2Discription = {}\n",
    "with open('Part2Discription', 'r') as f:\n",
    "    Part2Discription = json.load(f)\n",
    "query = '请问我可以对Brim做什么改动？'\n",
    "\n",
    "# 这里可以存储多个prompt模板，用来匹配用户输入prompt和哪个模板更匹配，如果匹配上了就按结构返回，没匹配上就自由返回\n",
    "prompt_template2 = f\"\"\"请基于以下内容回答问题，并将回答内容使用一个字典结构储存，其中包括两个key，一个key为'answer'，value为你对该问题的文本回答；第二个key为'data'，并返回对应的条目原文，不要翻译\n",
    "\n",
    "内容:\n",
    "{Part2Discription['cap']}\n",
    "query:\n",
    "{query}\n",
    "\"\"\"\n",
    "ragClient.pushUserMessage(prompt_template2)\n",
    "answer = ragClient.getandpushGptMsg()\n",
    "print (answer)\n",
    "\n",
    "# 2：对用户输入prompt进行编码，做embedding相似的编辑方向推荐"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('myconda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccc93251d6f721491c6fbc0c6bcbe4e9a605d28f77b9a8e19b15e1c61d18557e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
